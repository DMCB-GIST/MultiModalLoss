{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on synthetic data with two noise modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "from multi_modal_loss import MultiModalLoss\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "torch.cuda.set_device(0) \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0.0001, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >self.patience:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.task11= nn.Linear(2000, 500)\n",
    "        self.task21= nn.Linear(2000, 500)\n",
    "        self.task31= nn.Linear(2000, 500)\n",
    "        \n",
    "        self.task12= nn.Linear(500, 100)\n",
    "        self.task22= nn.Linear(500, 100)\n",
    "        self.task32= nn.Linear(500, 100)\n",
    "\n",
    "        self.task13= nn.Linear(100, 20)\n",
    "        self.task23= nn.Linear(100, 20)\n",
    "        self.task33= nn.Linear(100, 20)\n",
    "\n",
    "        self.task14= nn.Linear(20, 2)\n",
    "        self.task24= nn.Linear(20, 2)\n",
    "        self.task34= nn.Linear(20, 2)\n",
    "        \n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward_one(self,xg,xm,xs):\n",
    "        xg = self.task11(xg)\n",
    "        xm = self.task21(xm)\n",
    "        xs = self.task31(xs)         \n",
    "\n",
    "        xg = self.task12(xg)\n",
    "        xm = self.task22(xm)\n",
    "        xs = self.task32(xs)         \n",
    "        \n",
    "        xg = self.task13(xg)\n",
    "        xm = self.task23(xm)\n",
    "        xs = self.task33(xs)      \n",
    "        \n",
    "        xg = self.task14(xg)\n",
    "        xm = self.task24(xm)\n",
    "        xs = self.task34(xs)     \n",
    "        \n",
    "        xg = self.softmax(xg)\n",
    "        xm = self.softmax(xm)\n",
    "        xs = self.softmax(xs)\n",
    "        \n",
    "        return xg,xm,xs, xg+xm+xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('/data/sim_train_1_EHH.csv', header=0, index_col=None).values\n",
    "train_2 = pd.read_csv('/data/sim_train_2_EHH.csv', header=0, index_col=None).values\n",
    "train_3 = pd.read_csv('/data/sim_train_3_EHH.csv', header=0, index_col=None).values\n",
    "\n",
    "test_1 = pd.read_csv('/data/sim_test_1_EHH.csv', header=0, index_col=None).values\n",
    "test_2 = pd.read_csv('/data/sim_test_2_EHH.csv', header=0, index_col=None).values\n",
    "test_3 = pd.read_csv('/data/sim_test_3_EHH.csv', header=0, index_col=None).values\n",
    "\n",
    "train_y = pd.read_csv('/data/sim_train_y_EHH.csv', header=0, index_col=None).values\n",
    "test_y = pd.read_csv('/data/sim_test_y_EHH.csv', header=0, index_col=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500000], Loss: 0.6958\n",
      "Epoch [100/500000], Loss: 0.1983\n",
      "Epoch [200/500000], Loss: 0.1839\n",
      "Epoch [300/500000], Loss: 0.1677\n",
      "Epoch [400/500000], Loss: 0.1613\n",
      "Epoch [500/500000], Loss: 0.1607\n",
      "Epoch [600/500000], Loss: 0.1606\n",
      "Epoch [700/500000], Loss: 0.1603\n",
      "Epoch [800/500000], Loss: 0.1600\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "earlyStoppingPatience = 100\n",
    "learningRate= 0.0005\n",
    "weightDecay =0.0001\n",
    "\n",
    "y_train = train_y.flatten().astype(int)\n",
    "y_test = test_y.flatten().astype(int)\n",
    "\n",
    "Xg = torch.tensor(train_1, dtype=torch.float32).cuda()\n",
    "Xm = torch.tensor(train_2, dtype=torch.float32).cuda()\n",
    "Xs = torch.tensor(train_3, dtype=torch.float32).cuda()\n",
    "\n",
    "Xg_test = torch.tensor(test_1, dtype=torch.float32).cuda()\n",
    "Xm_test = torch.tensor(test_2, dtype=torch.float32).cuda()\n",
    "Xs_test = torch.tensor(test_3, dtype=torch.float32).cuda()\n",
    "\n",
    "y = torch.LongTensor(y_train).cuda()\n",
    "\n",
    "ds = TensorDataset(Xg, Xm,Xs,y)\n",
    "loader  = DataLoader(ds, batch_size=y_train.shape[0],shuffle=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_epochs = 500000 \n",
    "net = DNN()\n",
    "net = net.to(device)\n",
    "early_stopping = EarlyStopping(patience=earlyStoppingPatience, verbose=False)\n",
    "CELoss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam([{\"params\": net.parameters(), \"lr\": learningRate,  \"weight_decay\":weightDecay}])\n",
    "\n",
    "for epoch in (range(num_epochs)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        xg,xm,xs, y = data\n",
    "        _,_,_, output = net.forward_one(xg,xm,xs)\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = CELoss(output, y.view(-1))\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    early_stopping(running_loss, net)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    if (epoch+1) % 100 == 0 or epoch == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1,  num_epochs, running_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUM  ACC 0.69580\n"
     ]
    }
   ],
   "source": [
    "test1,test2,test3,output = net.forward_one(Xg_test.clone().detach(),Xm_test.clone().detach(),Xs_test.clone().detach())\n",
    "prob_test = output.cpu().detach().numpy()\n",
    "\n",
    "prob_test = softmax(prob_test, axis=1)\n",
    "prob_test =prob_test[:,1] \n",
    "print (\"SUM  ACC %.5f\" %(accuracy_score(list(y_test),np.where(prob_test > 0.5, 1, 0) ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histofram of the predicted classification probability conditioned on true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Proportion'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "data = pd.concat([pd.DataFrame(np.stack([test1.cpu().detach().numpy()[:5000,0].T,test2.cpu().detach().numpy()[:5000,0].T,test3.cpu().detach().numpy()[:5000,0].T])).T,pd.DataFrame(np.stack([test1.cpu().detach().numpy()[5000:,1].T,test2.cpu().detach().numpy()[5000:,1].T,test3.cpu().detach().numpy()[5000:,1].T])).T])\n",
    "sns.histplot(data=data,bins=10, palette=['#029e9e', '#d9601a','#db1a5e'], stat=\"proportion\", alpha  = 0.65, edgecolor='k', linewidth=2,common_norm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
